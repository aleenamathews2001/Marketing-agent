# nodes/completion.py

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
import logging
import json



from core.state import MarketingState
import sys
import os
import docx  # For direct schema reading
import json

# REMOVED ChromaDB import to prevent database lock conflicts
# (The MCP process uses ChromaDB; the Server process should not touch it essentially)




# 
def get_available_fields(obj_type):
    """
    Reads schema_metadata.json to returns a list of all available fields for the object.
    Returns: [{label: 'Status', name: 'Status', type: 'picklist', picklistValues: [...]}, ...]
    """
    try:
        # Construct path to schema_metadata.json (same dir as server.py)
        base_dir = os.path.dirname(os.path.abspath(__file__)) # nodes/
        project_root = os.path.dirname(base_dir)              # project/
        schema_path = os.path.join(project_root, "schema_metadata.json")
        
        if not os.path.exists(schema_path):
             print(f"‚ùå SCHEMA ERROR: File not found at {schema_path}")
             return []
             
        with open(schema_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            
        print(f"üîç DEBUG: Searching schema for object '{obj_type}'")
            
        # Handle List vs Dict structure (Schema is a List)
        if isinstance(data, list):
            # Case-insensitive lookup
            obj_meta = next((item for item in data if item["object"].lower() == str(obj_type).lower()), {})
        else:
            obj_meta = data.get(obj_type, {})

        fields = obj_meta.get("fields", [])
        print(f"üîç DEBUG: Found {len(fields)} fields for '{obj_type}'")
        
        # Transform for UI
        ui_fields = []
        for f in fields:
             # Transform Picklist Values (List of strings -> List of dicts for LWC)
             raw_pvals = f.get("picklistValues", [])
             ui_pvals = [{"label": str(v), "value": str(v)} for v in raw_pvals]

             ui_fields.append({
                 "label": f.get("FieldLabel") or f.get("label") or f.get("apiname") or f.get("name"),
                 "name": f.get("apiname") or f.get("name"),
                 "type": (f.get("datatype") or f.get("type", "string")).lower(),
                 "picklistValues": ui_pvals
             })
        return ui_fields
    except Exception as e:
        logging.error(f"Error reading schema for UI: {e}")
        return []


def get_need_value_fields_direct(obj_type):
    """
    Reads the lightweight schema_metadata.json to find needvalue fields.
    This avoids:
    1. Reading the heavy Word doc (slow)
    2. Initializing ChromaDB (locks/crashes)
    """
    try:
        # Use the JSON generated by init_schema.py
        current_dir = os.path.dirname(os.path.abspath(__file__))
        json_path = os.path.join(current_dir, '..', 'schema_metadata.json')
        
        # Fallback to direct doc read if JSON missing (robustness)
        if not os.path.exists(json_path):
             return []

        with open(json_path, 'r') as f:
            data = json.load(f)
        
        # Search for object
        for item in data:
            if item.get('object', '').lower() == str(obj_type).lower():
                fields = item.get('fields', [])
                need_vals = []
                for f in fields:
                    # Handle sloppy keys (e.g. 'needvalue ' with space)
                    nv = f.get('needvalue') or f.get('needvalue ') or f.get('needValue') or f.get('NeedValue')
                    if str(nv).lower() == 'true':
                        need_vals.append(f.get('apiname'))
                return need_vals
    except Exception as e:
        logging.warning(f"Error reading schema metadata: {e}")
    return []


def format_tool_results_for_summary(tool_results: list) -> str:
    """
    Format tool results in a clean way for LLM summary.
    Shows IDs only if there are 3 or fewer results.
    """
    if not tool_results:
        return "No operations performed"
    
    formatted_lines = []
    show_ids = len(tool_results) <= 3
    
    for idx, result in enumerate(tool_results, 1):
        tool_name = result.get('tool_name', 'Unknown tool')
        status = result.get('status', 'unknown')
        request = result.get('request', {})
        response = result.get('response', {})
        
        # Extract response content
        response_text = ""
        if hasattr(response, 'content') and response.content:
            try:
                response_text = response.content[0].text if response.content else ""
            except:
                response_text = str(response)
        
        # Parse response to get ID if available AND Check for Errors
        record_id = None
        is_error_content = False
        
        if response_text:
            try:
                parsed = json.loads(response_text)
                record_id = parsed.get('id')
                
                # Check for explicit error flags in the JSON content
                if parsed.get('error') or parsed.get('errorCode') or parsed.get('success') is False:
                    is_error_content = True
            except:
                # If text contains "error" or "exception" broadly
                if "error" in response_text.lower() and "success" not in response_text.lower():
                    is_error_content = True

        # Override status if content indicates failure
        if is_error_content:
            status = "FAILED (App Error)"
        
        # Build summary line
        line = f"{idx}. {tool_name} - {status}"
        if show_ids and record_id:
            line += f" (ID: {record_id})"
        
        formatted_lines.append(line)
    
    return "\n".join(formatted_lines)


async def completion_node(state: MarketingState) -> MarketingState:
    """
    Final node that dynamically summarizes only the operations that were performed.
    """
    logging.info("üèÅ Completing workflow and generating summary...")

    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0
    )

    # Collect all performed operations dynamically
    operations_performed = []
    
    # Check for MCP service results
    if state.get('salesforce_data'):
        sf_data = state['salesforce_data']
        tool_results = sf_data.get('tool_results', [])
        if tool_results:
            operations_performed.append({
                'service': 'Salesforce',
                'summary': sf_data.get('execution_summary', {}),
                'tool_results': tool_results
            })
    
    if state.get('brevo_results'):
        brevo_data = state['brevo_results']
        tool_results = brevo_data.get('tool_results', [])
        if tool_results:
            operations_performed.append({
                'service': 'Brevo',
                'summary': brevo_data.get('execution_summary', {}),
                'tool_results': tool_results
            })
    
    if state.get('linkly_links'):
        linkly_data = state['linkly_links']
        tool_results = linkly_data.get('tool_results', [])
        if tool_results:
            operations_performed.append({
                'service': 'Linkly',
                'summary': linkly_data.get('execution_summary', {}),
                'tool_results': tool_results
            })

    # If no operations, return early
    if not operations_performed:
        no_op_message = "No operations were performed."
        state["final_response"] = no_op_message
        state.setdefault("messages", [])
        state["messages"].append(AIMessage(content=no_op_message))
        state["current_agent"] = "completion"
        return state

    # Build context for LLM
    operations_context = []
    for op in operations_performed:
        service = op['service']
        summary = op['summary']
        tool_results_formatted = format_tool_results_for_summary(op['tool_results'])
        
        op_text = f"""**{service}**
- Total operations: {summary.get('total_calls', 0)}
- Successful: {summary.get('successful_calls', 0)}
- Failed: {summary.get('failed_calls', 0)}

Operations performed:
{tool_results_formatted}
"""
        operations_context.append(op_text)

    context = "\n\n".join(operations_context)

    # üîç ANALYZE FOR MISSING VALUES (Smart Reporting)
    missing_value_report = ""
    is_review_mode = False
    review_context = ""
    
    try:
        if state.get('salesforce_data'):
            tool_results = state['salesforce_data'].get('tool_results', [])
            
            # Check for PROPOSAL ACTION (Generic Review)
            is_review_mode = False
            proposal_details = {}
            contact_count = 0
            related_records_list = []
            
            for result in tool_results:
                tool_name = result.get('tool_name', '').lower()
                status = result.get('status', '')
                
                # Check for contact fetching
                if 'run_dynamic_soql' in tool_name and status == 'success':
                    try:
                        resp = result.get('response', {})
                        # Try to get list of contacts
                        if hasattr(resp, 'content'):
                            text_content = resp.content[0].text if resp.content else "[]"
                            contacts_data = json.loads(text_content)
                            
                            # Handle {records: [...]} structure vs [...]
                            records_list = []
                            if isinstance(contacts_data, dict) and 'records' in contacts_data:
                                records_list = contacts_data['records']
                            elif isinstance(contacts_data, list):
                                records_list = contacts_data
                                
                            contact_count = len(records_list)
                            
                            # Extract useful info for UI (Id, Name)
                            related_records_list = []
                            for c in records_list:
                                related_records_list.append({
                                    "Id": c.get("Id"),
                                    "Name": c.get("Name", "Unknown"),
                                    "Email": c.get("Email", "")
                                })
                        elif isinstance(resp, list):
                             contact_count = len(resp)
                             related_records_list = []
                             for c in resp:
                                related_records_list.append({
                                    "Id": c.get("Id"),
                                    "Name": c.get("Name", "Unknown"),
                                    "Email": c.get("Email", "")
                                })
                    except Exception as e:
                        logging.error(f"Error extracting contact details: {e}")
                        contact_count = 0

                # Check for PROPOSAL
                if 'propose_action' in tool_name:
                    # is_review_mode = True  <-- Moved to strict check below
                    # Extract proposal data
                    try:
                        resp_obj = result.get('response', {})
                        if isinstance(resp_obj, dict):
                            proposal_details = resp_obj.get('proposal', {})
                        elif hasattr(resp_obj, 'content'):
                             pass 
                    except:
                        pass
                    
                    if not proposal_details:
                         req = result.get('request', {})
                         proposal_details = {
                             "object_name": req.get("object_name"),
                             "fields": req.get("fields", {}),
                             "action_type": req.get("action_type", "create")
                         }

                    # STRICT CHECK: Only trigger Review UI for Create/Update
                    # Sending email or other actions should not block here.
                    action_type = proposal_details.get("action_type", "create").lower()
                    if action_type in ["create", "update", "upsert"]:
                        is_review_mode = True
                    else:
                        is_review_mode = False
                        logging.info(f"‚è≠Ô∏è Skipping Review UI for action type: {action_type}")




            if is_review_mode:
                # üöÄ INJECT AVAILABLE FIELDS for UI Dropdowns
                object_name = proposal_details.get("object_name", "Record")
                available_fields = get_available_fields(object_name)

                # üõë STOP & RETURN STRUCTURED PROPOSAL
                fields_list = []
                p_fields = proposal_details.get("fields", {})
                
                # Helper for lookup
                def get_label_for_field(fname, avail):
                    # Case-insensitive match
                    for f in avail:
                        if f['name'].lower() == str(fname).lower():
                            return f['label']
                    return fname # Fallback to API Name

                for k, v in p_fields.items():
                    # üõ°Ô∏è SAFETY NET: Filter out nulls, empty strings, or "Need Value" placeholders
                    if v is None or str(v).strip() == "" or str(v).lower() == "need value":
                        logging.warning(f"üßπ Filtered out empty/invalid field: {k}={v}")
                        continue
                        
                    fields_list.append({
                        "name": k,
                        "value": v,
                        "label": get_label_for_field(k, available_fields) # ‚úÖ Use Pretty Label
                    })

                proposal_payload = {
                    "object": object_name,
                    "fields": fields_list,
                    "contact_count": contact_count,
                    "related_records": related_records_list, # PASS THE LIST
                    "available_fields": available_fields,    # <--- NEW DATA
                    "generated_by": "Agent"
                }

                # Construct flexible message
                base_msg = f"I‚Äôm ready to create the {proposal_payload['object']} with the details below."
                if contact_count > 0:
                    base_msg += f" Found {contact_count} related records."
                base_msg += "Please review, make any changes if needed ."
                # Create the JSON string
                final_json = json.dumps({
                    "type": "review_proposal",
                    "proposal": proposal_payload,
                    "message": base_msg
                })
                
                state["final_response"] = final_json
                state.setdefault("messages", [])
                state["messages"].append(AIMessage(content=final_json))
                state["current_agent"] = "completion"
                logging.info("‚è∏Ô∏è Pausing for Proposal Review")
                return state

            # üß† SMART CONTEXT: If user is sending emails, don't nag about the Campaign object details
            is_email_task = 'send' in state.get('user_goal', '').lower() and 'email' in state.get('user_goal', '').lower()
            
            for result in tool_results:
                msg = ""
                # Check for Create or Upsert operations
                tool_name = result.get('tool_name', '').lower()
                if 'create' in tool_name or 'upsert' in tool_name:
                    request_data = result.get('request', {})
                    obj_type = request_data.get('object_name') or request_data.get('sobject')
                    
                    if obj_type:
                        # Skip Campaign validation if we are just sending emails (Campaign is just a vehicle)
                        if is_email_task and obj_type.lower() == 'campaign':
                            continue

                        # Get Need Value fields from Schema DIRECTLY (Case-Insensitive)
                        need_val_names = get_need_value_fields_direct(obj_type)
                        logging.info(f"üîç Validation Check for {obj_type}: NeedValues={need_val_names}")
                            
                        # Check what was sent
                        sent_fields = request_data.get('fields', {})
                        if not sent_fields and 'json_data' in request_data:
                            try:
                                sent_fields = json.loads(request_data['json_data'])
                            except:
                                pass
                                
                        logging.info(f"üì§ Sent Fields: {sent_fields.keys()}")
                                
                        # 1. Identify Defaults Applied
                        defaults_applied = []
                        if 'StartDate' in sent_fields:
                            defaults_applied.append(f"StartDate ({sent_fields['StartDate']})")
                        if 'EndDate' in sent_fields:
                            defaults_applied.append(f"EndDate ({sent_fields['EndDate']})")
                        if 'Status' in sent_fields and sent_fields.get('Status') == 'Planned':
                            defaults_applied.append("Status (Planned)")
                            
                        # 2. Identify Missing Recommended Values - DISABLED per user request
                        # missing_recs = []
                        # for field_name in need_val_names:
                        #     if field_name not in sent_fields:
                        #         missing_recs.append(field_name)
                        
                        # ‚úÖ Restore Provided Logic (needed for summary)
                        provided_recs = []
                        ignored_fields = ['Name', 'attributes']
                        for field_name, field_val in sent_fields.items():
                             is_default = False
                             if field_name == 'StartDate' or field_name == 'EndDate': is_default = True
                             if field_name == 'Status' and field_val == 'Planned': is_default = True
                             
                             if not is_default and field_name not in ignored_fields:
                                 provided_recs.append(f"{field_name} ({field_val})")
                        
                        logging.info(f"‚úÖ Provided Recs: {provided_recs}")

                        # Build the message segment
                        if provided_recs:
                            msg += f"\n- **Values Provided**: {', '.join(provided_recs)}"
                            
                        if defaults_applied:
                            msg += f"\n- **Defaults Applied**: {', '.join(defaults_applied)}"
                        
                        # Removed "Missing Values" prompting as Review Step handles this.
                
                if msg:
                     missing_value_report += f"\n\nFor {obj_type} record:{msg}"

    except Exception as e:
        logging.warning(f"Error analyzing missing values: {e}")

    summary_prompt = f"""Summarize what was accomplished in 1-2 short sentences.

User's Goal:
{state['user_goal']}

Operations Performed:
{context}
{review_context}

Analysis of Defaults & Missing Values:
{missing_value_report}

Instructions:
- Write a **professional, friendly, and natural summary**.
- Confirm the creation and the **Exact Name**.
- **Crucial**: You MUST mention the specific values set for **StartDate, EndDate, and Status** if they are present in the 'Provided Values' or 'Defaults' section. Weave them into the sentence naturally.
- Mention contact assignment if applicable.
- Avoid robotic lists; use natural language (e.g. "...scheduled for 2025-12-01 with a status of 'Planned'.").
- **DO NOT** use markdown formatting like `**bold**`; plain text only.

Example Style (Natural):
"Success! I've created the Campaign 'Summer Launch' set to start on 2025-12-01 and end on 2026-01-01 with a 'Planned' status. I've also linked the 12 found contacts to it."

Summary:"""

    try:
        response = await llm.ainvoke([HumanMessage(content=summary_prompt)])
        final_summary = response.content.strip()

        # Add execution details if user might want them
        if any(op['summary'].get('failed_calls', 0) > 0 for op in operations_performed):
            final_summary += "\n\nNote: Some operations encountered errors. Check the details above for more information."

        state["final_response"] = final_summary
        state.setdefault("messages", [])
        state["messages"].append(AIMessage(content=final_summary))
        state["current_agent"] = "completion"

        logging.info("‚úÖ Workflow completed successfully")

    except Exception as e:
        logging.error(f"Completion node error: {e}")
        
        # Fallback summary if LLM fails
        fallback = "Workflow completed. "
        for op in operations_performed:
            fallback += f"{op['service']}: {op['summary'].get('successful_calls', 0)} successful operations. "
        
        state["final_response"] = fallback
        state["error"] = str(e)

    return state